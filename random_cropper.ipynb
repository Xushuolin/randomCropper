{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a31909-38df-4b3f-bb7b-be1e2cd9a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import math\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import parameters as iap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31941c-9a55-4b54-8e4d-6a4914c46483",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff8f17d-9a4d-496f-b6c5-0a3bf0ddbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_format = '.jpg'\n",
    "labels_path = 'labels/'\n",
    "path = 'images/'\n",
    "cropped_images_path = 'cropped_images/'\n",
    "cropped_labels_path = 'cropped_labels/'\n",
    "new_labels = 'new_labels/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133339df-5341-4352-9bb4-dcf3b3e64851",
   "metadata": {},
   "source": [
    "## Remove Very Small Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57324fbf-fc53-49a7-9a2b-f891f5c9fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0001\n",
    "for i in range(10):\n",
    "    for item in os.listdir(labels_path):\n",
    "        ann = np.loadtxt(labels_path+item)\n",
    "        ann = ann.tolist()\n",
    "\n",
    "        # multiple objects\n",
    "        if type(ann[0]) == list:\n",
    "            for obj in ann:\n",
    "                if obj[3]*obj[4] < threshold:\n",
    "                    ann.remove(obj)\n",
    "            if ann != []:\n",
    "                np.savetxt(labels_path+item, ann, fmt='%.10g')\n",
    "            else:\n",
    "                os.remove(path+item.replace(item[-4:], img_format))\n",
    "                os.remove(labels_path+item)\n",
    "\n",
    "        # single object    \n",
    "        else:\n",
    "            if ann[3]*ann[4] < threshold:\n",
    "                os.remove(labels_path+item)\n",
    "                os.remove(path+item.replace(item[-4:], img_format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3dbc7-3ed5-4c04-92df-bddaf1df7927",
   "metadata": {},
   "source": [
    "## Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a60c3-ffff-4bfe-b202-d7d69b84980a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0.0003\n",
    "for i in range(5):\n",
    "    for item in os.listdir(labels_path):\n",
    "        ann = np.loadtxt(labels_path+item).tolist()\n",
    "        width = 512\n",
    "        height = 512\n",
    "        i = 0\n",
    "        margin = 30\n",
    "\n",
    "\n",
    "        # multiple objects\n",
    "        if type(ann[0]) == list:\n",
    "            img_name = item.replace(item[-4:], '.jpg')\n",
    "            image = imageio.imread(os.path.join(path,img_name))\n",
    "            item = item.replace(item[-4:], '')\n",
    "            ann_copy = ann.copy()\n",
    "            \n",
    "            h, w ,c = image.shape\n",
    "            # specify bboxes\n",
    "            bbs = BoundingBoxesOnImage([\n",
    "                BoundingBox(x1=(obj[1]-obj[3]/2)*w, x2=(obj[1]+obj[3]/2)*w, y1=(obj[2]-obj[4]/2)*h, y2=(obj[2]+obj[4]/2)*h) for obj in ann]\n",
    "                , shape=image.shape)\n",
    "\n",
    "\n",
    "            for element in ann:\n",
    "                annotation = []\n",
    "                # names\n",
    "                i += 1\n",
    "                new_item_name = f'{item}_{i}'\n",
    "                new_img_name = new_item_name + '.jpg'\n",
    "                new_label_name = new_item_name +'.txt'\n",
    "\n",
    "                if element[3]*element[4] < threshold:\n",
    "                    # Transformations\n",
    "                    seq = iaa.Sequential([\n",
    "                    iaa.CropToFixedSize(width=width, height=height, position=((1-element[1]),(1-element[2])))\n",
    "                    ])\n",
    "                    # Output\n",
    "                    image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
    "                    # make sure object are completly inside (px)\n",
    "                    for e in bbs_aug:\n",
    "                        xmin=e[0][0]\n",
    "                        ymin=e[0][1]\n",
    "                        xmax=e[1][0]\n",
    "                        ymax=e[1][1]\n",
    "\n",
    "                        if (xmin > 0 - margin) and (width + margin > xmax) and (ymin > 0 - margin) and (height + margin > ymax):\n",
    "                            if xmin < 0:\n",
    "                                xmin = xmin + abs(xmin)\n",
    "                            if xmax > width:\n",
    "                                xmax = xmax - abs(width-xmax)\n",
    "                            if ymin < 0:\n",
    "                                ymin = ymin + abs(ymin)\n",
    "                            if ymax > height:\n",
    "                                ymax = ymax - abs(height-ymax)\n",
    "\n",
    "\n",
    "                            x_center = (xmax+xmin)/(2*width)\n",
    "                            y_center = (ymax+ymin)/(2*height)\n",
    "                            obj_width = (xmax-xmin)/width\n",
    "                            obj_height = (ymax-ymin)/height\n",
    "\n",
    "                            annot = [int(0), x_center, y_center, obj_width, obj_height]\n",
    "                            annotation.append(annot)\n",
    "\n",
    "                    ann_copy.remove(element)\n",
    "                    if annotation != []:\n",
    "                        np.savetxt(os.path.join(cropped_labels_path, new_label_name), annotation, fmt='%.10g')\n",
    "                        io.imsave(os.path.join(cropped_images_path, new_img_name), image_aug)\n",
    "            \n",
    "            if ann_copy != []:\n",
    "                np.savetxt(os.path.join(labels_path, item+'.txt'), ann_copy, fmt='%.10g')\n",
    "                io.imsave(os.path.join(path, img_name), image)\n",
    "            if ann_copy == []:\n",
    "                os.remove(os.path.join(labels_path, item+'.txt'))\n",
    "                os.remove(os.path.join(path, img_name))\n",
    "\n",
    "\n",
    "\n",
    "        # single object    \n",
    "        else:\n",
    "            if ann[3]*ann[4] < threshold:\n",
    "                obj = ann\n",
    "\n",
    "                # load image\n",
    "                img_name = item.replace(item[-4:],'.jpg')\n",
    "                image = io.imread(os.path.join(path, img_name))\n",
    "\n",
    "                # extract h, w\n",
    "                h, w , c = image.shape\n",
    "\n",
    "                bbs = BoundingBoxesOnImage([\n",
    "                    BoundingBox(x1=(obj[1]-obj[3]/2)*w, x2=(obj[1]+obj[3]/2)*w, y1=(obj[2]-obj[4]/2)*h, y2=(obj[2]+obj[4]/2)*h)]\n",
    "                    , shape=image.shape)\n",
    "\n",
    "                seq = iaa.Sequential([\n",
    "                iaa.CropToFixedSize(width=width, height=height, position=((1-obj[1]),(1-obj[2])))\n",
    "                ])\n",
    "\n",
    "                # Output\n",
    "                image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
    "\n",
    "                # make sure object are completly inside (px)\n",
    "                e = bbs_aug\n",
    "                xmin=e[0][0][0]\n",
    "                ymin=e[0][0][1]\n",
    "                xmax=e[0][1][0]\n",
    "                ymax=e[0][1][1]\n",
    "\n",
    "                if (xmin > 0 - margin) and (width + margin > xmax) and (ymin > 0 - margin) and (height + margin > ymax):\n",
    "                    if xmin < 0:\n",
    "                        xmin = xmin + abs(xmin)\n",
    "                    if xmax > width:\n",
    "                        xmax = xmax - abs(width-xmax)\n",
    "                    if ymin < 0:\n",
    "                        ymin = ymin + abs(ymin)\n",
    "                    if ymax > height:\n",
    "                        ymax = ymax - abs(height-ymax)\n",
    "\n",
    "                    x_center = (xmax+xmin)/(2*width)\n",
    "                    y_center = (ymax+ymin)/(2*height)\n",
    "                    obj_width = (xmax-xmin)/width\n",
    "                    obj_height = (ymax-ymin)/height\n",
    "\n",
    "                    annot = [int(0), x_center, y_center, obj_width, obj_height]\n",
    "\n",
    "\n",
    "                np.savetxt(os.path.join(cropped_labels_path, 'single-'+item), annot, newline=' ', fmt='%.10g')\n",
    "                io.imsave(os.path.join(cropped_images_path, 'single-'+img_name), image_aug)\n",
    "                os.remove(os.path.join(labels_path, item))\n",
    "                os.remove(os.path.join(path, img_name))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29671aae-3512-49b0-99f7-c730787a9163",
   "metadata": {},
   "source": [
    "# Bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b69d74-e088-4358-9807-4bcd68783eb8",
   "metadata": {},
   "source": [
    "* Needs more than 1 run\n",
    "* not sure how position=() really works! (Some images are very similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6588c8b-8ebc-47db-85ad-54f082740156",
   "metadata": {},
   "source": [
    "# Remove Similiar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eae0d79-c82e-49f0-888a-60e4717b7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71dab24-8690-48fb-9c01-c45705f5b23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = .4\n",
    "for im1 in os.listdir(cropped_images_path):\n",
    "    for im2 in os.listdir(cropped_images_path):\n",
    "        if im1 != im2:\n",
    "            image1 = cv.imread(os.path.join(cropped_images_path,im1))\n",
    "            image2 = cv.imread(os.path.join(cropped_images_path,im2))\n",
    "            try:\n",
    "                value = ssim(image1, image2, multichannel=True)\n",
    "                if value > threshold:\n",
    "                    os.remove(os.path.join(cropped_images_path,im2))\n",
    "                    os.remove(os.path.join(cropped_labels_path,im2.replace(im2[-4:], '.txt')))\n",
    "            except ValueError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b05f86-1c69-413c-80d0-a9e88b8b7109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.096686868795659"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim(cv.imread('3691_1.jpg'), cv.imread('3691_2.jpg'), multichannel=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
